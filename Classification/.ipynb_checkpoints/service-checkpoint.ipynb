{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9e62d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86f5fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as fn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from pos_encoding import PositionalEmbedding\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "464aa013",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7f1c3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docker version 20.10.24, build 297e128\n"
     ]
    }
   ],
   "source": [
    "!docker -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfbd80c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74c50697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 22.11.1\n"
     ]
    }
   ],
   "source": [
    "!conda --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c6fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker pull nvcr.io/nvidia/tritonserver:23.01-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09dc363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, num_layers, dim_ffd, num_classes, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.dim_ffd = dim_ffd\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        self.positional_embed = PositionalEmbedding(max_len=2000, embed_size=self.embed_size)\n",
    "#         nn.init.trunc_normal_(self.positional_embed, std=0.2)\n",
    "        assert self.embed_size % self.num_heads == 0, \"number of heads must divide evenly into embedding size\"\n",
    "\n",
    "        self.layer = nn.TransformerEncoderLayer(d_model=self.embed_size, nhead=self.num_heads, dim_feedforward=self.dim_ffd, dropout=self.dropout)\n",
    "        self.encoder = nn.TransformerEncoder(self.layer, num_layers=self.num_layers)\n",
    "\n",
    "        self.fc = nn.Linear(self.embed_size, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.positional_embed(self.embedding(x))\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        out = self.fc(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e7fc763",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load('vocab.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091c4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "EMB_SIZE = 512\n",
    "N_HEADS = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 64\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 10\n",
    "PAD, UNK = 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0e59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "200c35a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(vocab_size=VOCAB_SIZE, embed_size=EMB_SIZE, num_heads=N_HEADS, num_layers=NUM_ENCODER_LAYERS, dim_ffd=FFN_HID_DIM, num_classes=NUM_CLASSES)\n",
    "# model = model.to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afefc245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll create the model directory structure for each of our PyTorch \n",
    "import os\n",
    "directory = 'models/transformer-encoder/1'\n",
    "os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "547ab60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint):\n",
    "    print(\"Loading checkpoint.....\")\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82e6dcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint.....\n"
     ]
    }
   ],
   "source": [
    "load_checkpoint(torch.load('my_model.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a6d8c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder(\n",
      "  (embedding): Embedding(110934, 512)\n",
      "  (positional_embed): PositionalEmbedding()\n",
      "  (layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45be3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1c99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc94bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d9dca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "    name: \"transformer-encoder\"\n",
    "    platform: \"pytorch\"\n",
    "    max_batch_size: 32\n",
    "    input[\n",
    "        {\n",
    "            name:'input_0'\n",
    "            data_type: TYPE_FP32\n",
    "            dims: [512]\n",
    "        }\n",
    "    ]\n",
    "    output{\n",
    "        name: \"output_0\"\n",
    "        data_type: TYPE_FP32\n",
    "        dims: [ 4 ]\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "794d45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/transformer-encoder/config.pbtxt', 'w') as file:\n",
    "    file.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 -v/full/path/to/docs/examples/model_repository:/models nvcr.io/nvidia/tritonserver:23.01-py3 tritonserver --model-repository=/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bea2ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 127.0.0.1:8000...\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\n",
      "> GET /v2/health/ready HTTP/1.1\n",
      "\n",
      "> Host: localhost:8000\n",
      "\n",
      "> User-Agent: curl/8.0.1\n",
      "\n",
      "> Accept: */*\n",
      "\n",
      "> \n",
      "\n",
      "< HTTP/1.1 200 OK\n",
      "\n",
      "< Content-Length: 0\n",
      "\n",
      "< Content-Type: text/plain\n",
      "\n",
      "< \n",
      "\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/health/ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3fbf6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef52bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"Request for unknown model: 'transformer-encoder' is not found\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 127.0.0.1:8000...\n",
      "* Connected to localhost (127.0.0.1) port 8000 (#0)\n",
      "> GET /v2/models/transformer-encoder HTTP/1.1\n",
      "\n",
      "> Host: localhost:8000\n",
      "\n",
      "> User-Agent: curl/8.0.1\n",
      "\n",
      "> Accept: */*\n",
      "\n",
      "> \n",
      "\n",
      "< HTTP/1.1 400 Bad Request\n",
      "\n",
      "< Content-Type: application/json\n",
      "\n",
      "< Content-Length: 73\n",
      "\n",
      "< \n",
      "\n",
      "{ [73 bytes data]\n",
      "\n",
      "100    73  100    73    0     0  24737      0 --:--:-- --:--:-- --:--:-- 36500\n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "!curl -v localhost:8000/v2/models/transformer-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f61e61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
